{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc5130e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy pandas transformers scikit-learn hf_xet 'accelerate>=0.26.0' datasets\n",
    "# %pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e45ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "script_dir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "parent_dir = os.path.abspath(os.path.join(script_dir, os.pardir))\n",
    "sys.path.append(script_dir)\n",
    "from utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56fa6ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5d547a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"https://github.com/food-hazard-detection-semeval-2025/food-hazard-detection-semeval-2025.github.io/blob/main/data/\"\n",
    "\n",
    "train = pd.read_csv(os.path.join(DATA_PATH, \"incidents_train.csv?raw=true\"))\n",
    "valid = pd.read_csv(os.path.join(DATA_PATH, \"incidents_valid.csv?raw=true\"))\n",
    "test = pd.read_csv(os.path.join(DATA_PATH, \"incidents_test.csv?raw=true\"))\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'st1_task': True,  # True dla ST1 (kategorie), False dla ST2 (wektory)\n",
    "    'use_both_text_title': True,  # Czy używać title+text czy tylko title\n",
    "    'max_features': 10000,  # Ograniczenie TF-IDF dla wydajności\n",
    "    'random_state': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87fa2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FOOD HAZARD DETECTION - IMPROVED BASELINE ===\n",
      "Task: ST1 (Categories)\n",
      "Features: Title + Text\n",
      "Train size: 5082, Valid size: 565, Test size: 997\n",
      "\n",
      "2. Data analysis...\n",
      "\n",
      "ST1 Statistics:\n",
      "Unique hazards: 10\n",
      "Unique products: 22\n",
      "Most common hazard: allergens (1854 samples)\n",
      "Most common product: meat, egg and dairy products (1434 samples)\n",
      "\n",
      "3. Feature engineering...\n",
      "Creating TF-IDF features...\n",
      "TF-IDF shape: (5082, 10000)\n",
      "\n",
      "4. Label preparation...\n",
      "\n",
      "5. Training models...\n",
      "Training hazard classifier...\n",
      "Training product classifier...\n",
      "\n",
      "6. Making predictions...\n",
      "\n",
      "=== VALIDATION RESULTS ===\n",
      "Hazard F1: 0.6892\n",
      "Product F1: 0.5335\n",
      "Final Score: 0.6113\n",
      "\n",
      "=== TEST RESULTS ===\n",
      "Hazard F1: 0.6173\n",
      "Product F1: 0.5783\n",
      "Final Score: 0.5978\n",
      "\n",
      "=== DETAILED ANALYSIS FOR REPORT ===\n",
      "\n",
      "Baseline (Majority Classifier): 0.0352\n",
      "Our Model: 0.5978\n",
      "Improvement: 0.5626\n",
      "\n",
      "=== ERROR ANALYSIS (ST1) ===\n",
      "\n",
      "Top 5 most confused hazard pairs:\n",
      "  allergens → fraud: 31 times\n",
      "  biological → organoleptic aspects: 11 times\n",
      "  fraud → allergens: 11 times\n",
      "  biological → chemical: 9 times\n",
      "  allergens → foreign bodies: 5 times\n",
      "\n",
      "Worst performing hazard classes:\n",
      "  migration: F1=0.000 (n=1)\n",
      "  other hazard: F1=0.426 (n=26)\n",
      "  organoleptic aspects: F1=0.467 (n=10)\n",
      "\n",
      "==================================================\n",
      "SUMMARY FOR REPORT\n",
      "==================================================\n",
      "Task: ST1\n",
      "Features: Title + Text\n",
      "Method: TF-IDF + Logistic Regression with Class Weights\n",
      "Validation_F1_Hazard: 0.6892\n",
      "Validation_F1_Product: 0.5335\n",
      "Validation_Final_Score: 0.6113\n",
      "Test_F1_Hazard: 0.6173\n",
      "Test_F1_Product: 0.5783\n",
      "Test_Final_Score: 0.5978\n",
      "Baseline_Score: 0.0352\n",
      "Improvement: 0.5626\n",
      "\n",
      "Results saved to: results_st1.csv\n",
      "\n",
      "=== EXPERIMENT COMPLETED ===\n",
      "Configuration used: {'st1_task': True, 'use_both_text_title': True, 'max_features': 10000, 'random_state': 42}\n",
      "Final ST1 Score: 0.5978\n",
      "\n",
      "Reference (Competition):\n",
      "Best ST1 result: 0.8223 (Anastasia)\n",
      "BERT baseline: ~0.667\n",
      "Your result: 0.5978\n"
     ]
    }
   ],
   "source": [
    "print(\"=== FOOD HAZARD DETECTION - IMPROVED BASELINE ===\")\n",
    "print(f\"Task: {'ST1 (Categories)' if CONFIG['st1_task'] else 'ST2 (Vectors)'}\")\n",
    "print(f\"Features: {'Title + Text' if CONFIG['use_both_text_title'] else 'Title only'}\")\n",
    "\n",
    "print(f\"Train size: {len(train)}, Valid size: {len(valid)}, Test size: {len(test)}\")\n",
    "\n",
    "# 2. DATA ANALYSIS & PREPROCESSING\n",
    "print(\"\\n2. Data analysis...\")\n",
    "\n",
    "# Wybór labelów na podstawie zadania\n",
    "if CONFIG['st1_task']:\n",
    "    hazard_col = 'hazard-category'\n",
    "    product_col = 'product-category'\n",
    "    task_name = \"ST1\"\n",
    "else:\n",
    "    hazard_col = 'hazard'\n",
    "    product_col = 'product'\n",
    "    task_name = \"ST2\"\n",
    "\n",
    "# Statystyki\n",
    "hazard_counts = train[hazard_col].value_counts()\n",
    "product_counts = train[product_col].value_counts()\n",
    "\n",
    "print(f\"\\n{task_name} Statistics:\")\n",
    "print(f\"Unique hazards: {len(hazard_counts)}\")\n",
    "print(f\"Unique products: {len(product_counts)}\")\n",
    "print(f\"Most common hazard: {hazard_counts.index[0]} ({hazard_counts.iloc[0]} samples)\")\n",
    "print(f\"Most common product: {product_counts.index[0]} ({product_counts.iloc[0]} samples)\")\n",
    "\n",
    "# 3. FEATURE ENGINEERING\n",
    "print(\"\\n3. Feature engineering...\")\n",
    "\n",
    "# Przygotowanie tekstów\n",
    "train_texts = prepare_text_features(train, CONFIG)\n",
    "valid_texts = prepare_text_features(valid, CONFIG)\n",
    "test_texts = prepare_text_features(test, CONFIG)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "print(\"Creating TF-IDF features...\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=CONFIG['max_features'],\n",
    "    ngram_range=(1, 2),  # 1-gramy i 2-gramy\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_valid = vectorizer.transform(valid_texts) \n",
    "X_test = vectorizer.transform(test_texts)\n",
    "\n",
    "print(f\"TF-IDF shape: {X_train.shape}\")\n",
    "\n",
    "# 4. LABEL PREPARATION\n",
    "print(\"\\n4. Label preparation...\")\n",
    "\n",
    "# Etykiety dla hazard\n",
    "y_train_hazard = train[hazard_col]\n",
    "y_valid_hazard = valid[hazard_col]\n",
    "y_test_hazard = test[hazard_col]\n",
    "\n",
    "# Etykiety dla product\n",
    "y_train_product = train[product_col]\n",
    "y_valid_product = valid[product_col]\n",
    "y_test_product = test[product_col]\n",
    "\n",
    "# 5. MODEL TRAINING\n",
    "print(\"\\n5. Training models...\")\n",
    "\n",
    "# Class weights dla niezbalansowanych danych\n",
    "hazard_classes = np.unique(y_train_hazard)\n",
    "product_classes = np.unique(y_train_product)\n",
    "\n",
    "hazard_weights = compute_class_weight('balanced', classes=hazard_classes, y=y_train_hazard)\n",
    "product_weights = compute_class_weight('balanced', classes=product_classes, y=y_train_product)\n",
    "\n",
    "hazard_weight_dict = dict(zip(hazard_classes, hazard_weights))\n",
    "product_weight_dict = dict(zip(product_classes, product_weights))\n",
    "\n",
    "# Modele z class weights\n",
    "hazard_model = LogisticRegression(\n",
    "    class_weight=hazard_weight_dict,\n",
    "    max_iter=1000,\n",
    "    random_state=CONFIG['random_state']\n",
    ")\n",
    "\n",
    "product_model = LogisticRegression(\n",
    "    class_weight=product_weight_dict,\n",
    "    max_iter=1000,\n",
    "    random_state=CONFIG['random_state']\n",
    ")\n",
    "\n",
    "print(\"Training hazard classifier...\")\n",
    "hazard_model.fit(X_train, y_train_hazard)\n",
    "\n",
    "print(\"Training product classifier...\")\n",
    "product_model.fit(X_train, y_train_product)\n",
    "\n",
    "# 7. PREDICTIONS AND EVALUATION\n",
    "print(\"\\n6. Making predictions...\")\n",
    "\n",
    "# Predykcje na validation set\n",
    "hazard_pred_valid = hazard_model.predict(X_valid)\n",
    "product_pred_valid = product_model.predict(X_valid)\n",
    "\n",
    "# Predykcje na test set\n",
    "hazard_pred_test = hazard_model.predict(X_test)\n",
    "product_pred_test = product_model.predict(X_test)\n",
    "\n",
    "# Ocena na validation set\n",
    "print(\"\\n=== VALIDATION RESULTS ===\")\n",
    "valid_scores = compute_food_hazard_score(\n",
    "    y_valid_hazard.values, y_valid_product.values,\n",
    "    hazard_pred_valid, product_pred_valid\n",
    ")\n",
    "\n",
    "print(f\"Hazard F1: {valid_scores['f1_hazards']:.4f}\")\n",
    "print(f\"Product F1: {valid_scores['f1_products']:.4f}\")\n",
    "print(f\"Final Score: {valid_scores['final_score']:.4f}\")\n",
    "\n",
    "# Ocena na test set\n",
    "print(\"\\n=== TEST RESULTS ===\")\n",
    "test_scores = compute_food_hazard_score(\n",
    "    y_test_hazard.values, y_test_product.values,\n",
    "    hazard_pred_test, product_pred_test\n",
    ")\n",
    "\n",
    "print(f\"Hazard F1: {test_scores['f1_hazards']:.4f}\")\n",
    "print(f\"Product F1: {test_scores['f1_products']:.4f}\")\n",
    "print(f\"Final Score: {test_scores['final_score']:.4f}\")\n",
    "\n",
    "# 8. DETAILED ANALYSIS FOR REPORT\n",
    "print(\"\\n=== DETAILED ANALYSIS FOR REPORT ===\")\n",
    "\n",
    "# Porównanie z majority classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_hazard = DummyClassifier(strategy='most_frequent')\n",
    "dummy_product = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "dummy_hazard.fit(X_train, y_train_hazard)\n",
    "dummy_product.fit(X_train, y_train_product)\n",
    "\n",
    "dummy_hazard_pred = dummy_hazard.predict(X_test)\n",
    "dummy_product_pred = dummy_product.predict(X_test)\n",
    "\n",
    "dummy_scores = compute_food_hazard_score(\n",
    "    y_test_hazard.values, y_test_product.values,\n",
    "    dummy_hazard_pred, dummy_product_pred\n",
    ")\n",
    "\n",
    "print(f\"\\nBaseline (Majority Classifier): {dummy_scores['final_score']:.4f}\")\n",
    "print(f\"Our Model: {test_scores['final_score']:.4f}\")\n",
    "print(f\"Improvement: {test_scores['final_score'] - dummy_scores['final_score']:.4f}\")\n",
    "\n",
    "# Analiza błędów - najczęściej mylone klasy\n",
    "print(f\"\\n=== ERROR ANALYSIS ({task_name}) ===\")\n",
    "\n",
    "# Top 5 najczęściej mylonych hazard classes\n",
    "hazard_errors = []\n",
    "for true_label, pred_label in zip(y_test_hazard, hazard_pred_test):\n",
    "    if true_label != pred_label:\n",
    "        hazard_errors.append((true_label, pred_label))\n",
    "\n",
    "if hazard_errors:\n",
    "    hazard_error_counter = Counter(hazard_errors)\n",
    "    print(f\"\\nTop 5 most confused hazard pairs:\")\n",
    "    for (true_h, pred_h), count in hazard_error_counter.most_common(5):\n",
    "        print(f\"  {true_h} → {pred_h}: {count} times\")\n",
    "\n",
    "# Klasy z najniższym F1\n",
    "hazard_f1_per_class = f1_score(y_test_hazard, hazard_pred_test, average=None, labels=hazard_classes)\n",
    "worst_hazard_classes = sorted(zip(hazard_classes, hazard_f1_per_class), key=lambda x: x[1])[:3]\n",
    "\n",
    "print(f\"\\nWorst performing hazard classes:\")\n",
    "for class_name, f1 in worst_hazard_classes:\n",
    "    class_count = sum(y_test_hazard == class_name)\n",
    "    print(f\"  {class_name}: F1={f1:.3f} (n={class_count})\")\n",
    "\n",
    "# 9. RESULTS SUMMARY FOR REPORT\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY FOR REPORT\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "results_summary = {\n",
    "    'Task': task_name,\n",
    "    'Features': 'Title + Text' if CONFIG['use_both_text_title'] else 'Title only',\n",
    "    'Method': 'TF-IDF + Logistic Regression with Class Weights',\n",
    "    'Validation_F1_Hazard': f\"{valid_scores['f1_hazards']:.4f}\",\n",
    "    'Validation_F1_Product': f\"{valid_scores['f1_products']:.4f}\",\n",
    "    'Validation_Final_Score': f\"{valid_scores['final_score']:.4f}\",\n",
    "    'Test_F1_Hazard': f\"{test_scores['f1_hazards']:.4f}\",\n",
    "    'Test_F1_Product': f\"{test_scores['f1_products']:.4f}\",\n",
    "    'Test_Final_Score': f\"{test_scores['final_score']:.4f}\",\n",
    "    'Baseline_Score': f\"{dummy_scores['final_score']:.4f}\",\n",
    "    'Improvement': f\"{test_scores['final_score'] - dummy_scores['final_score']:.4f}\"\n",
    "}\n",
    "\n",
    "for key, value in results_summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# 10. SAVE RESULTS\n",
    "results_df = pd.DataFrame([results_summary])\n",
    "results_df.to_csv(f'results_{task_name.lower()}.csv', index=False)\n",
    "print(f\"\\nResults saved to: results_{task_name.lower()}.csv\")\n",
    "\n",
    "print(\"\\n=== EXPERIMENT COMPLETED ===\")\n",
    "print(f\"Configuration used: {CONFIG}\")\n",
    "print(f\"Final {task_name} Score: {test_scores['final_score']:.4f}\")\n",
    "\n",
    "# Szybkie porównanie z wynikami z konkursu\n",
    "if CONFIG['st1_task']:\n",
    "    print(f\"\\nReference (Competition):\")\n",
    "    print(f\"Best ST1 result: 0.8223 (Anastasia)\")\n",
    "    print(f\"BERT baseline: ~0.667\")\n",
    "    print(f\"Your result: {test_scores['final_score']:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nReference (Competition):\")\n",
    "    print(f\"Best ST2 result: 0.5473 (SRCB)\")\n",
    "    print(f\"BERT baseline: ~0.498\") \n",
    "    print(f\"Your result: {test_scores['final_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb432af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'st1_task': False,  # True dla ST1 (kategorie), False dla ST2 (wektory)\n",
    "    'use_both_text_title': True,  # Czy używać title+text czy tylko title\n",
    "    'max_features': 10000,  # Ograniczenie TF-IDF dla wydajności\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "print(\"=== FOOD HAZARD DETECTION - IMPROVED BASELINE ===\")\n",
    "print(f\"Task: {'ST1 (Categories)' if CONFIG['st1_task'] else 'ST2 (Vectors)'}\")\n",
    "print(f\"Features: {'Title + Text' if CONFIG['use_both_text_title'] else 'Title only'}\")\n",
    "\n",
    "# 1. LOAD DATA\n",
    "print(\"\\n1. Loading datasets...\")\n",
    "DATA_PATH = \"https://github.com/food-hazard-detection-semeval-2025/food-hazard-detection-semeval-2025.github.io/blob/main/data/\"\n",
    "\n",
    "train = pd.read_csv(os.path.join(DATA_PATH, \"incidents_train.csv?raw=true\"))\n",
    "valid = pd.read_csv(os.path.join(DATA_PATH, \"incidents_valid.csv?raw=true\"))\n",
    "test = pd.read_csv(os.path.join(DATA_PATH, \"incidents_test.csv?raw=true\"))\n",
    "\n",
    "print(f\"Train size: {len(train)}, Valid size: {len(valid)}, Test size: {len(test)}\")\n",
    "\n",
    "# 2. DATA ANALYSIS & PREPROCESSING\n",
    "print(\"\\n2. Data analysis...\")\n",
    "\n",
    "# Wybór labelów na podstawie zadania\n",
    "if CONFIG['st1_task']:\n",
    "    hazard_col = 'hazard-category'\n",
    "    product_col = 'product-category'\n",
    "    task_name = \"ST1\"\n",
    "else:\n",
    "    hazard_col = 'hazard'\n",
    "    product_col = 'product'\n",
    "    task_name = \"ST2\"\n",
    "\n",
    "# Statystyki\n",
    "hazard_counts = train[hazard_col].value_counts()\n",
    "product_counts = train[product_col].value_counts()\n",
    "\n",
    "print(f\"\\n{task_name} Statistics:\")\n",
    "print(f\"Unique hazards: {len(hazard_counts)}\")\n",
    "print(f\"Unique products: {len(product_counts)}\")\n",
    "print(f\"Most common hazard: {hazard_counts.index[0]} ({hazard_counts.iloc[0]} samples)\")\n",
    "print(f\"Most common product: {product_counts.index[0]} ({product_counts.iloc[0]} samples)\")\n",
    "\n",
    "# 3. FEATURE ENGINEERING\n",
    "print(\"\\n3. Feature engineering...\")\n",
    "\n",
    "\n",
    "\n",
    "# Przygotowanie tekstów\n",
    "train_texts = prepare_text_features(train, CONFIG)\n",
    "valid_texts = prepare_text_features(valid, CONFIG)\n",
    "test_texts = prepare_text_features(test, CONFIG)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "print(\"Creating TF-IDF features...\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=CONFIG['max_features'],\n",
    "    ngram_range=(1, 2),  # 1-gramy i 2-gramy\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_valid = vectorizer.transform(valid_texts) \n",
    "X_test = vectorizer.transform(test_texts)\n",
    "\n",
    "print(f\"TF-IDF shape: {X_train.shape}\")\n",
    "\n",
    "# 4. LABEL PREPARATION\n",
    "print(\"\\n4. Label preparation...\")\n",
    "\n",
    "# Etykiety dla hazard\n",
    "y_train_hazard = train[hazard_col]\n",
    "y_valid_hazard = valid[hazard_col]\n",
    "y_test_hazard = test[hazard_col]\n",
    "\n",
    "# Etykiety dla product\n",
    "y_train_product = train[product_col]\n",
    "y_valid_product = valid[product_col]\n",
    "y_test_product = test[product_col]\n",
    "\n",
    "# 5. MODEL TRAINING\n",
    "print(\"\\n5. Training models...\")\n",
    "\n",
    "# Class weights dla niezbalansowanych danych\n",
    "hazard_classes = np.unique(y_train_hazard)\n",
    "product_classes = np.unique(y_train_product)\n",
    "\n",
    "hazard_weights = compute_class_weight('balanced', classes=hazard_classes, y=y_train_hazard)\n",
    "product_weights = compute_class_weight('balanced', classes=product_classes, y=y_train_product)\n",
    "\n",
    "hazard_weight_dict = dict(zip(hazard_classes, hazard_weights))\n",
    "product_weight_dict = dict(zip(product_classes, product_weights))\n",
    "\n",
    "# Modele z class weights\n",
    "hazard_model = LogisticRegression(\n",
    "    class_weight=hazard_weight_dict,\n",
    "    max_iter=1000,\n",
    "    random_state=CONFIG['random_state']\n",
    ")\n",
    "\n",
    "product_model = LogisticRegression(\n",
    "    class_weight=product_weight_dict,\n",
    "    max_iter=1000,\n",
    "    random_state=CONFIG['random_state']\n",
    ")\n",
    "\n",
    "print(\"Training hazard classifier...\")\n",
    "hazard_model.fit(X_train, y_train_hazard)\n",
    "\n",
    "print(\"Training product classifier...\")\n",
    "product_model.fit(X_train, y_train_product)\n",
    "\n",
    "# 6. EVALUATION FUNCTION\n",
    "\n",
    "\n",
    "# 7. PREDICTIONS AND EVALUATION\n",
    "print(\"\\n6. Making predictions...\")\n",
    "\n",
    "# Predykcje na validation set\n",
    "hazard_pred_valid = hazard_model.predict(X_valid)\n",
    "product_pred_valid = product_model.predict(X_valid)\n",
    "\n",
    "# Predykcje na test set\n",
    "hazard_pred_test = hazard_model.predict(X_test)\n",
    "product_pred_test = product_model.predict(X_test)\n",
    "\n",
    "# Ocena na validation set\n",
    "print(\"\\n=== VALIDATION RESULTS ===\")\n",
    "valid_scores = compute_food_hazard_score(\n",
    "    y_valid_hazard.values, y_valid_product.values,\n",
    "    hazard_pred_valid, product_pred_valid\n",
    ")\n",
    "\n",
    "print(f\"Hazard F1: {valid_scores['f1_hazards']:.4f}\")\n",
    "print(f\"Product F1: {valid_scores['f1_products']:.4f}\")\n",
    "print(f\"Final Score: {valid_scores['final_score']:.4f}\")\n",
    "\n",
    "# Ocena na test set\n",
    "print(\"\\n=== TEST RESULTS ===\")\n",
    "test_scores = compute_food_hazard_score(\n",
    "    y_test_hazard.values, y_test_product.values,\n",
    "    hazard_pred_test, product_pred_test\n",
    ")\n",
    "\n",
    "print(f\"Hazard F1: {test_scores['f1_hazards']:.4f}\")\n",
    "print(f\"Product F1: {test_scores['f1_products']:.4f}\")\n",
    "print(f\"Final Score: {test_scores['final_score']:.4f}\")\n",
    "\n",
    "# 8. DETAILED ANALYSIS FOR REPORT\n",
    "print(\"\\n=== DETAILED ANALYSIS FOR REPORT ===\")\n",
    "\n",
    "# Porównanie z majority classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_hazard = DummyClassifier(strategy='most_frequent')\n",
    "dummy_product = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "dummy_hazard.fit(X_train, y_train_hazard)\n",
    "dummy_product.fit(X_train, y_train_product)\n",
    "\n",
    "dummy_hazard_pred = dummy_hazard.predict(X_test)\n",
    "dummy_product_pred = dummy_product.predict(X_test)\n",
    "\n",
    "dummy_scores = compute_food_hazard_score(\n",
    "    y_test_hazard.values, y_test_product.values,\n",
    "    dummy_hazard_pred, dummy_product_pred\n",
    ")\n",
    "\n",
    "print(f\"\\nBaseline (Majority Classifier): {dummy_scores['final_score']:.4f}\")\n",
    "print(f\"Our Model: {test_scores['final_score']:.4f}\")\n",
    "print(f\"Improvement: {test_scores['final_score'] - dummy_scores['final_score']:.4f}\")\n",
    "\n",
    "# Analiza błędów - najczęściej mylone klasy\n",
    "print(f\"\\n=== ERROR ANALYSIS ({task_name}) ===\")\n",
    "\n",
    "# Top 5 najczęściej mylonych hazard classes\n",
    "hazard_errors = []\n",
    "for true_label, pred_label in zip(y_test_hazard, hazard_pred_test):\n",
    "    if true_label != pred_label:\n",
    "        hazard_errors.append((true_label, pred_label))\n",
    "\n",
    "if hazard_errors:\n",
    "    hazard_error_counter = Counter(hazard_errors)\n",
    "    print(f\"\\nTop 5 most confused hazard pairs:\")\n",
    "    for (true_h, pred_h), count in hazard_error_counter.most_common(5):\n",
    "        print(f\"  {true_h} → {pred_h}: {count} times\")\n",
    "\n",
    "# Klasy z najniższym F1\n",
    "hazard_f1_per_class = f1_score(y_test_hazard, hazard_pred_test, average=None, labels=hazard_classes)\n",
    "worst_hazard_classes = sorted(zip(hazard_classes, hazard_f1_per_class), key=lambda x: x[1])[:3]\n",
    "\n",
    "print(f\"\\nWorst performing hazard classes:\")\n",
    "for class_name, f1 in worst_hazard_classes:\n",
    "    class_count = sum(y_test_hazard == class_name)\n",
    "    print(f\"  {class_name}: F1={f1:.3f} (n={class_count})\")\n",
    "\n",
    "# 9. RESULTS SUMMARY FOR REPORT\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY FOR REPORT\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "results_summary = {\n",
    "    'Task': task_name,\n",
    "    'Features': 'Title + Text' if CONFIG['use_both_text_title'] else 'Title only',\n",
    "    'Method': 'TF-IDF + Logistic Regression with Class Weights',\n",
    "    'Validation_F1_Hazard': f\"{valid_scores['f1_hazards']:.4f}\",\n",
    "    'Validation_F1_Product': f\"{valid_scores['f1_products']:.4f}\",\n",
    "    'Validation_Final_Score': f\"{valid_scores['final_score']:.4f}\",\n",
    "    'Test_F1_Hazard': f\"{test_scores['f1_hazards']:.4f}\",\n",
    "    'Test_F1_Product': f\"{test_scores['f1_products']:.4f}\",\n",
    "    'Test_Final_Score': f\"{test_scores['final_score']:.4f}\",\n",
    "    'Baseline_Score': f\"{dummy_scores['final_score']:.4f}\",\n",
    "    'Improvement': f\"{test_scores['final_score'] - dummy_scores['final_score']:.4f}\"\n",
    "}\n",
    "\n",
    "for key, value in results_summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# 10. SAVE RESULTS\n",
    "results_df = pd.DataFrame([results_summary])\n",
    "results_df.to_csv(f'results_{task_name.lower()}.csv', index=False)\n",
    "print(f\"\\nResults saved to: results_{task_name.lower()}.csv\")\n",
    "\n",
    "print(\"\\n=== EXPERIMENT COMPLETED ===\")\n",
    "print(f\"Configuration used: {CONFIG}\")\n",
    "print(f\"Final {task_name} Score: {test_scores['final_score']:.4f}\")\n",
    "\n",
    "# Szybkie porównanie z wynikami z konkursu\n",
    "if CONFIG['st1_task']:\n",
    "    print(f\"\\nReference (Competition):\")\n",
    "    print(f\"  Best ST1 result: 0.8223 (Anastasia)\")\n",
    "    print(f\"  BERT baseline: ~0.667\")\n",
    "    print(f\"  Your result: {test_scores['final_score']:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nReference (Competition):\")\n",
    "    print(f\"  Best ST2 result: 0.5473 (SRCB)\")\n",
    "    print(f\"  BERT baseline: ~0.498\") \n",
    "    print(f\"  Your result: {test_scores['final_score']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
