{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy pandas transformers scikit-learn hf_xet 'accelerate>=0.26.0' datasets\n",
    "# %pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62024308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "script_dir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "parent_dir = os.path.abspath(os.path.join(script_dir, os.pardir))\n",
    "sys.path.append(script_dir)\n",
    "from utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "import warnings\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "CONFIG = {\n",
    "    'st1_task': True,  # Change to False for ST2\n",
    "    'enhanced_tfidf': True,\n",
    "    'feature_engineering': True,\n",
    "    'max_features': 15000,  # Increased from 10000\n",
    "    'ngram_range': (1, 3),  # Added trigrams\n",
    "    'min_df': 1,           # More inclusive\n",
    "    'max_df': 0.9,         # Less restrictive\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# # Back-to-basics + XGBoost approach\n",
    "# CONFIG = {\n",
    "#     'st1_task': True,  # Change to False for ST2\n",
    "#     'models_to_try': ['logreg', 'xgb'],  # Which models to test\n",
    "#     'ensemble': True,   # Whether to combine models\n",
    "#     'grid_search_tfidf': True,  # Try different TF-IDF params\n",
    "#     'random_state': 42\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b880cc",
   "metadata": {},
   "source": [
    "### 1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfebf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n1. Loading data...\")\n",
    "\n",
    "DATA_PATH = \"https://github.com/food-hazard-detection-semeval-2025/food-hazard-detection-semeval-2025.github.io/blob/main/data/\"\n",
    "\n",
    "train = pd.read_csv(os.path.join(DATA_PATH, \"incidents_train.csv?raw=true\"))\n",
    "valid = pd.read_csv(os.path.join(DATA_PATH, \"incidents_valid.csv?raw=true\"))\n",
    "test = pd.read_csv(os.path.join(DATA_PATH, \"incidents_test.csv?raw=true\"))\n",
    "\n",
    "task_name = \"ST1\" if CONFIG['st1_task'] else \"ST2\"\n",
    "print(\"=== ENHANCED FOOD HAZARD DETECTION - FIXED ===\")\n",
    "print(f\"Task: {task_name}\")\n",
    "print(f\"Enhanced TF-IDF: {CONFIG['enhanced_tfidf']}\")\n",
    "print(f\"Feature Engineering: {CONFIG['feature_engineering']}\")\n",
    "print(f\"Dataset sizes - Train: {len(train)}, Valid: {len(valid)}, Test: {len(test)}\")\n",
    "\n",
    "# Task selection\n",
    "if CONFIG['st1_task']:\n",
    "    hazard_col = 'hazard-category'\n",
    "    product_col = 'product-category'\n",
    "else:\n",
    "    hazard_col = 'hazard'\n",
    "    product_col = 'product'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da4166",
   "metadata": {},
   "source": [
    "### 2. Enhanced Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a71cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n2. Enhanced text preprocessing...\")\n",
    "\n",
    "# Apply enhanced preprocessing\n",
    "train = enhanced_text_preparation(train)\n",
    "valid = enhanced_text_preparation(valid)\n",
    "test = enhanced_text_preparation(test)\n",
    "\n",
    "print(\"Enhanced text preprocessing completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff6ae1a",
   "metadata": {},
   "source": [
    "### 3. Safe Feature Engineering (no problematic features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0256b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n3. Safe feature engineering...\")\n",
    "\n",
    "if CONFIG['feature_engineering']:\n",
    "    print(\"  Creating safe engineered features...\")\n",
    "    train_features = create_safe_features(train)\n",
    "    valid_features = create_safe_features(valid)\n",
    "    test_features = create_safe_features(test)\n",
    "    \n",
    "    print(f\"Created {train_features.shape[1]} safe engineered features\")\n",
    "    print(f\"Feature names: {list(train_features.columns[:10])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5173ebbb",
   "metadata": {},
   "source": [
    "### 4. Enhanced TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad80068",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n4. Enhanced TF-IDF vectorization...\")\n",
    "\n",
    "if CONFIG['enhanced_tfidf']:\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=CONFIG['max_features'],\n",
    "        ngram_range=CONFIG['ngram_range'],\n",
    "        min_df=CONFIG['min_df'],\n",
    "        max_df=CONFIG['max_df'],\n",
    "        stop_words='english',\n",
    "        sublinear_tf=True,\n",
    "        norm='l2',\n",
    "        smooth_idf=True\n",
    "    )\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=2,\n",
    "        max_df=0.95,\n",
    "        stop_words='english'\n",
    "    )\n",
    "\n",
    "print(f\"  TF-IDF config: max_features={CONFIG['max_features']}, ngrams={CONFIG['ngram_range']}\")\n",
    "\n",
    "# Create TF-IDF features\n",
    "X_train_tfidf = vectorizer.fit_transform(train['combined_text'])\n",
    "X_valid_tfidf = vectorizer.transform(valid['combined_text'])\n",
    "X_test_tfidf = vectorizer.transform(test['combined_text'])\n",
    "\n",
    "print(f\"TF-IDF shape: {X_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88c265a",
   "metadata": {},
   "source": [
    "### 5. Safe Feature Combination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badc6f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n5. Combining features safely...\")\n",
    "\n",
    "if CONFIG['feature_engineering']:\n",
    "    # Ensure all feature sets have the same columns\n",
    "    common_columns = train_features.columns.intersection(valid_features.columns).intersection(test_features.columns)\n",
    "    \n",
    "    train_features_safe = train_features[common_columns]\n",
    "    valid_features_safe = valid_features[common_columns]\n",
    "    test_features_safe = test_features[common_columns]\n",
    "    \n",
    "    print(f\"  Using {len(common_columns)} common engineered features\")\n",
    "    \n",
    "    # Scale engineered features\n",
    "    scaler = StandardScaler()\n",
    "    train_features_scaled = scaler.fit_transform(train_features_safe)\n",
    "    valid_features_scaled = scaler.transform(valid_features_safe)\n",
    "    test_features_scaled = scaler.transform(test_features_safe)\n",
    "    \n",
    "    # Combine TF-IDF + engineered features\n",
    "    X_train = hstack([X_train_tfidf, train_features_scaled])\n",
    "    X_valid = hstack([X_valid_tfidf, valid_features_scaled])\n",
    "    X_test = hstack([X_test_tfidf, test_features_scaled])\n",
    "    \n",
    "    print(f\"Combined features shape: {X_train.shape}\")\n",
    "    print(f\"TF-IDF: {X_train_tfidf.shape[1]}, Engineered: {len(common_columns)}\")\n",
    "else:\n",
    "    X_train = X_train_tfidf\n",
    "    X_valid = X_valid_tfidf\n",
    "    X_test = X_test_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8110b62",
   "metadata": {},
   "source": [
    "### 6. Prepare Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b207fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n6. Preparing labels...\")\n",
    "\n",
    "y_train_hazard = train[hazard_col].values\n",
    "y_valid_hazard = valid[hazard_col].values\n",
    "y_test_hazard = test[hazard_col].values\n",
    "\n",
    "y_train_product = train[product_col].values\n",
    "y_valid_product = valid[product_col].values\n",
    "y_test_product = test[product_col].values\n",
    "\n",
    "# Show class distribution\n",
    "hazard_counts = pd.Series(y_train_hazard).value_counts()\n",
    "product_counts = pd.Series(y_train_product).value_counts()\n",
    "\n",
    "print(f\"  Hazard classes: {len(hazard_counts)} (imbalance: {hazard_counts.iloc[0]/hazard_counts.iloc[-1]:.1f}x)\")\n",
    "print(f\"  Product classes: {len(product_counts)} (imbalance: {product_counts.iloc[0]/product_counts.iloc[-1]:.1f}x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bfd71e",
   "metadata": {},
   "source": [
    "### 7. Enhanced Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4002189",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n7. Training enhanced models...\")\n",
    "\n",
    "# Class weights\n",
    "hazard_classes = np.unique(y_train_hazard)\n",
    "product_classes = np.unique(y_train_product)\n",
    "\n",
    "hazard_weights = compute_class_weight('balanced', classes=hazard_classes, y=y_train_hazard)\n",
    "product_weights = compute_class_weight('balanced', classes=product_classes, y=y_train_product)\n",
    "\n",
    "hazard_weight_dict = dict(zip(hazard_classes, hazard_weights))\n",
    "product_weight_dict = dict(zip(product_classes, product_weights))\n",
    "\n",
    "# Enhanced Logistic Regression models\n",
    "print(\"  Training enhanced hazard classifier...\")\n",
    "hazard_model = LogisticRegression(\n",
    "    class_weight=hazard_weight_dict,\n",
    "    max_iter=2000,\n",
    "    C=1.0,\n",
    "    solver='liblinear',\n",
    "    random_state=CONFIG['random_state']\n",
    ")\n",
    "hazard_model.fit(X_train, y_train_hazard)\n",
    "\n",
    "print(\"  Training enhanced product classifier...\")\n",
    "product_model = LogisticRegression(\n",
    "    class_weight=product_weight_dict,\n",
    "    max_iter=2000,\n",
    "    C=1.0,\n",
    "    solver='liblinear',\n",
    "    random_state=CONFIG['random_state']\n",
    ")\n",
    "product_model.fit(X_train, y_train_product)\n",
    "\n",
    "print(\"Enhanced models trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8227402",
   "metadata": {},
   "source": [
    "### 8. Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c4ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n8. Making predictions...\")\n",
    "\n",
    "hazard_pred_valid = hazard_model.predict(X_valid)\n",
    "product_pred_valid = product_model.predict(X_valid)\n",
    "\n",
    "hazard_pred_test = hazard_model.predict(X_test)\n",
    "product_pred_test = product_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48329244",
   "metadata": {},
   "source": [
    "### 9. Results evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccd1c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n9. Results evaluation...\")\n",
    "# Validation results\n",
    "valid_scores = compute_food_hazard_score(\n",
    "    y_valid_hazard, y_valid_product,\n",
    "    hazard_pred_valid, product_pred_valid\n",
    ")\n",
    "\n",
    "# Test results\n",
    "test_scores = compute_food_hazard_score(\n",
    "    y_test_hazard, y_test_product,\n",
    "    hazard_pred_test, product_pred_test\n",
    ")\n",
    "\n",
    "print(\"\\n=== ENHANCED RESULTS ===\")\n",
    "print(f\"\\nValidation Results:\")\n",
    "print(f\"Hazard F1: {valid_scores['f1_hazards']:.4f}\")\n",
    "print(f\"Product F1: {valid_scores['f1_products']:.4f}\")\n",
    "print(f\"Final Score: {valid_scores['final_score']:.4f}\")\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"Hazard F1: {test_scores['f1_hazards']:.4f}\")\n",
    "print(f\"Product F1: {test_scores['f1_products']:.4f}\")\n",
    "print(f\"Final Score: {test_scores['final_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3b72b6",
   "metadata": {},
   "source": [
    "### 10. Comparison with Previous Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78302f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== IMPROVEMENT ANALYSIS ===\")\n",
    "\n",
    "# Previous baseline results (from your runs)\n",
    "if CONFIG['st1_task']:\n",
    "    previous_score = 0.5978\n",
    "    competition_bert = 0.667\n",
    "    competition_best = 0.8223\n",
    "else:\n",
    "    previous_score = 0.2546\n",
    "    competition_bert = 0.498\n",
    "    competition_best = 0.5473\n",
    "\n",
    "improvement = test_scores['final_score'] - previous_score\n",
    "print(f\"Previous baseline: {previous_score:.4f}\")\n",
    "print(f\"Enhanced model: {test_scores['final_score']:.4f}\")\n",
    "print(f\"Improvement: {improvement:+.4f}\")\n",
    "\n",
    "if improvement > 0:\n",
    "    print(f\"{improvement:.4f} improvement achieved!\")\n",
    "    if improvement > 0.05:\n",
    "        print(f\"SIGNIFICANT improvement!\")\n",
    "else:\n",
    "    print(f\"{abs(improvement):.4f} decrease\")\n",
    "\n",
    "print(f\"\\nCompetition Comparison ({task_name}):\")\n",
    "print(f\"Competition BERT baseline: {competition_bert:.4f}\")\n",
    "print(f\"Competition best: {competition_best:.4f}\")\n",
    "print(f\"Your enhanced result: {test_scores['final_score']:.4f}\")\n",
    "\n",
    "if test_scores['final_score'] > competition_bert:\n",
    "    print(f\"You beat the BERT baseline by {test_scores['final_score'] - competition_bert:.4f}!\")\n",
    "else:\n",
    "    gap = competition_bert - test_scores['final_score']\n",
    "    print(f\"Gap to BERT baseline: {gap:.4f}\")\n",
    "\n",
    "gap_to_best = competition_best - test_scores['final_score']\n",
    "print(f\"Gap to best result: {gap_to_best:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae3ef84",
   "metadata": {},
   "source": [
    "### 11. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== FEATURE ANALYSIS ===\")\n",
    "\n",
    "if CONFIG['feature_engineering']:\n",
    "    print(f\"Enhanced features used:\")\n",
    "    feature_list = train_features_safe.columns.tolist()\n",
    "    for i, feat in enumerate(feature_list):\n",
    "        if i < 15:  # Show first 15\n",
    "            print(f\"  {i+1:2d}. {feat}\")\n",
    "        elif i == 15:\n",
    "            print(f\"... and {len(feature_list)-15} more features\")\n",
    "            break\n",
    "\n",
    "# Quick feature effectiveness test\n",
    "print(f\"\\nFeature contribution analysis:\")\n",
    "print(f\"Total features: {X_train.shape[1]}\")\n",
    "print(f\"TF-IDF features: {X_train_tfidf.shape[1]}\")\n",
    "if CONFIG['feature_engineering']:\n",
    "    print(f\"Engineered features: {len(common_columns)}\")\n",
    "    print(f\"Feature engineering impact: {improvement:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd44b61",
   "metadata": {},
   "source": [
    "### 12. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a8c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary = {\n",
    "    'task': task_name,\n",
    "    'method': 'Enhanced TF-IDF + LogReg + Safe Feature Engineering',\n",
    "    'config': CONFIG,\n",
    "    'improvements': {\n",
    "        'enhanced_tfidf': CONFIG['enhanced_tfidf'],\n",
    "        'feature_engineering': CONFIG['feature_engineering'],\n",
    "        'total_features': X_train.shape[1],\n",
    "        'tfidf_features': X_train_tfidf.shape[1],\n",
    "        'engineered_features': len(common_columns) if CONFIG['feature_engineering'] else 0\n",
    "    },\n",
    "    'results': {\n",
    "        'validation': valid_scores,\n",
    "        'test': test_scores,\n",
    "        'improvement_over_baseline': float(improvement),\n",
    "        'previous_baseline': float(previous_score)\n",
    "    },\n",
    "    'competition_comparison': {\n",
    "        'competition_bert': float(competition_bert),\n",
    "        'competition_best': float(competition_best),\n",
    "        'beats_bert_baseline': bool(test_scores['final_score'] > competition_bert),\n",
    "        'gap_to_best': float(gap_to_best)\n",
    "    }\n",
    "}\n",
    "\n",
    "filename = f\"enhanced_safe_results_{task_name.lower()}.json\"\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nEnhanced results saved to {filename}\")\n",
    "\n",
    "print(\"\\n=== EXPERIMENT COMPLETED ===\")\n",
    "print(f\"Enhanced {task_name} Score: {test_scores['final_score']:.4f}\")\n",
    "print(f\"Improvement: {improvement:+.4f}\")\n",
    "\n",
    "# Actionable next steps\n",
    "print(f\"\\nNEXT STEPS BASED ON RESULTS:\")\n",
    "if improvement > 0.05:\n",
    "    print(\"EXCELLENT improvement! Ready for:\")\n",
    "    print(\"1. XGBoost ensemble (combine with LogReg)\")\n",
    "    print(\"2. Try ST2 with same approach\")\n",
    "    print(\"3. Advanced feature engineering\")\n",
    "elif improvement > 0:\n",
    "    print(\"Good improvement! Try:\")\n",
    "    print(\"1. XGBoost model\")\n",
    "    print(\"2. Different TF-IDF parameters\")\n",
    "    print(\"3. Ensemble methods\")\n",
    "else:\n",
    "    print(\"No improvement. Debug options:\")\n",
    "    print(\"1. Reduce complexity (fewer features)\")\n",
    "    print(\"2. Different ngram_range (1,2)\")\n",
    "    print(\"3. Traditional parameters\")\n",
    "\n",
    "# Performance summary\n",
    "if CONFIG['st1_task']:\n",
    "    if test_scores['final_score'] > 0.67:\n",
    "        print(\"\\nSTATUS: BERT baseline beaten! Ready for advanced techniques.\")\n",
    "    elif test_scores['final_score'] > 0.63:\n",
    "        print(\"\\nSTATUS: Close to BERT baseline. One more improvement should do it.\")\n",
    "    else:\n",
    "        print(\"\\nSTATUS: Need more work to reach BERT baseline.\")\n",
    "else:\n",
    "    if test_scores['final_score'] > 0.35:\n",
    "        print(\"\\nSTATUS: Good progress on difficult ST2 task.\")\n",
    "    else:\n",
    "        print(\"\\nSTATUS: ST2 still challenging, try data augmentation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee7bd53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa8b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"ST1\" if CONFIG['st1_task'] else \"ST2\"\n",
    "print(\"=== OPTIMIZED SIMPLE MODEL + ENSEMBLE ===\")\n",
    "print(f\"Task: {task_name}\")\n",
    "print(f\"Models to try: {CONFIG['models_to_try']}\")\n",
    "print(f\"Ensemble: {CONFIG['ensemble']}\")\n",
    "\n",
    "# Task selection\n",
    "if CONFIG['st1_task']:\n",
    "    hazard_col = 'hazard-category'\n",
    "    product_col = 'product-category'\n",
    "else:\n",
    "    hazard_col = 'hazard'\n",
    "    product_col = 'product'\n",
    "\n",
    "print(f\"Dataset sizes - Train: {len(train)}, Valid: {len(valid)}, Test: {len(test)}\")\n",
    "\n",
    "# 2. Simple but effective text preprocessing\n",
    "print(\"\\n2. Simple text preprocessing...\")\n",
    "\n",
    "train = simple_but_effective_preprocessing(train)\n",
    "valid = simple_but_effective_preprocessing(valid)\n",
    "test = simple_but_effective_preprocessing(test)\n",
    "\n",
    "print(\"Simple preprocessing completed\")\n",
    "\n",
    "# 3. TF-IDF Parameter Grid Search\n",
    "print(\"\\n3. TF-IDF parameter optimization...\")\n",
    "\n",
    "if CONFIG['grid_search_tfidf']:\n",
    "    # Test different TF-IDF configurations\n",
    "    tfidf_configs = [\n",
    "        {'name': 'original', 'max_features': 10000, 'ngram_range': (1, 2), 'min_df': 2, 'max_df': 0.95},\n",
    "        {'name': 'more_features', 'max_features': 15000, 'ngram_range': (1, 2), 'min_df': 2, 'max_df': 0.95},\n",
    "        {'name': 'trigrams', 'max_features': 10000, 'ngram_range': (1, 3), 'min_df': 2, 'max_df': 0.95},\n",
    "        {'name': 'less_restrictive', 'max_features': 10000, 'ngram_range': (1, 2), 'min_df': 1, 'max_df': 0.9},\n",
    "        {'name': 'balanced', 'max_features': 12000, 'ngram_range': (1, 2), 'min_df': 1, 'max_df': 0.92}\n",
    "    ]\n",
    "    \n",
    "    best_config = None\n",
    "    best_score = 0\n",
    "    tfidf_results = []\n",
    "    \n",
    "    # Labels for quick validation\n",
    "    y_train_hazard = train[hazard_col].values\n",
    "    y_valid_hazard = valid[hazard_col].values\n",
    "    y_train_product = train[product_col].values\n",
    "    y_valid_product = valid[product_col].values\n",
    "    \n",
    "    print(\"Testing TF-IDF configurations...\")\n",
    "    \n",
    "    for config in tfidf_configs:\n",
    "        print(f\"Testing {config['name']}...\")\n",
    "        \n",
    "        # Create vectorizer\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            max_features=config['max_features'],\n",
    "            ngram_range=config['ngram_range'],\n",
    "            min_df=config['min_df'],\n",
    "            max_df=config['max_df'],\n",
    "            stop_words='english'\n",
    "        )\n",
    "        \n",
    "        # Fit and transform\n",
    "        X_train_temp = vectorizer.fit_transform(train['combined_text'])\n",
    "        X_valid_temp = vectorizer.transform(valid['combined_text'])\n",
    "        \n",
    "        # Quick LogReg test\n",
    "        hazard_classes = np.unique(y_train_hazard)\n",
    "        hazard_weights = compute_class_weight('balanced', classes=hazard_classes, y=y_train_hazard)\n",
    "        hazard_weight_dict = dict(zip(hazard_classes, hazard_weights))\n",
    "        \n",
    "        quick_model = LogisticRegression(\n",
    "            class_weight=hazard_weight_dict,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        quick_model.fit(X_train_temp, y_train_hazard)\n",
    "        \n",
    "        # Quick evaluation\n",
    "        hazard_pred_temp = quick_model.predict(X_valid_temp)\n",
    "        quick_f1 = f1_score(y_valid_hazard, hazard_pred_temp, average='macro')\n",
    "        \n",
    "        tfidf_results.append({\n",
    "            'config': config['name'],\n",
    "            'f1_hazard': quick_f1,\n",
    "            'params': config\n",
    "        })\n",
    "        \n",
    "        print(f\"      {config['name']}: Hazard F1 = {quick_f1:.4f}\")\n",
    "        \n",
    "        if quick_f1 > best_score:\n",
    "            best_score = quick_f1\n",
    "            best_config = config\n",
    "    \n",
    "    print(f\"Best TF-IDF config: {best_config['name']} (F1: {best_score:.4f})\")\n",
    "    \n",
    "else:\n",
    "    # Use original configuration\n",
    "    best_config = {'max_features': 10000, 'ngram_range': (1, 2), 'min_df': 2, 'max_df': 0.95}\n",
    "\n",
    "# 4. Create final TF-IDF features\n",
    "print(\"\\n4. Creating final TF-IDF features...\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=best_config['max_features'],\n",
    "    ngram_range=best_config['ngram_range'],\n",
    "    min_df=best_config['min_df'],\n",
    "    max_df=best_config['max_df'],\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(train['combined_text'])\n",
    "X_valid = vectorizer.transform(valid['combined_text'])\n",
    "X_test = vectorizer.transform(test['combined_text'])\n",
    "\n",
    "print(f\"Final TF-IDF shape: {X_train.shape}\")\n",
    "\n",
    "# 5. Prepare labels\n",
    "y_train_hazard = train[hazard_col].values\n",
    "y_valid_hazard = valid[hazard_col].values\n",
    "y_test_hazard = test[hazard_col].values\n",
    "\n",
    "y_train_product = train[product_col].values\n",
    "y_valid_product = valid[product_col].values\n",
    "y_test_product = test[product_col].values\n",
    "\n",
    "# 6. Train Multiple Models\n",
    "print(\"\\n5. Training multiple models...\")\n",
    "\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# Class weights\n",
    "hazard_classes = np.unique(y_train_hazard)\n",
    "product_classes = np.unique(y_train_product)\n",
    "\n",
    "hazard_weights = compute_class_weight('balanced', classes=hazard_classes, y=y_train_hazard)\n",
    "product_weights = compute_class_weight('balanced', classes=product_classes, y=y_train_product)\n",
    "\n",
    "hazard_weight_dict = dict(zip(hazard_classes, hazard_weights))\n",
    "product_weight_dict = dict(zip(product_classes, product_weights))\n",
    "\n",
    "# Logistic Regression\n",
    "if 'logreg' in CONFIG['models_to_try']:\n",
    "    print(\"  Training Logistic Regression...\")\n",
    "    \n",
    "    models['logreg_hazard'] = LogisticRegression(\n",
    "        class_weight=hazard_weight_dict,\n",
    "        max_iter=1000,\n",
    "        C=1.0,\n",
    "        random_state=42\n",
    "    )\n",
    "    models['logreg_product'] = LogisticRegression(\n",
    "        class_weight=product_weight_dict,\n",
    "        max_iter=1000,\n",
    "        C=1.0,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    models['logreg_hazard'].fit(X_train, y_train_hazard)\n",
    "    models['logreg_product'].fit(X_train, y_train_product)\n",
    "    \n",
    "    predictions['logreg'] = {\n",
    "        'hazard_valid': models['logreg_hazard'].predict(X_valid),\n",
    "        'product_valid': models['logreg_product'].predict(X_valid),\n",
    "        'hazard_test': models['logreg_hazard'].predict(X_test),\n",
    "        'product_test': models['logreg_product'].predict(X_test)\n",
    "    }\n",
    "\n",
    "# XGBoost\n",
    "if 'xgb' in CONFIG['models_to_try']:\n",
    "    print(\"  Training XGBoost...\")\n",
    "    \n",
    "    # XGBoost with class weights\n",
    "    models['xgb_hazard'] = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    models['xgb_product'] = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Convert sparse matrix to dense for XGBoost\n",
    "    X_train_dense = X_train.toarray()\n",
    "    X_valid_dense = X_valid.toarray()\n",
    "    X_test_dense = X_test.toarray()\n",
    "    \n",
    "    # Calculate sample weights for XGBoost\n",
    "    hazard_sample_weights = np.array([hazard_weight_dict[y] for y in y_train_hazard])\n",
    "    product_sample_weights = np.array([product_weight_dict[y] for y in y_train_product])\n",
    "    \n",
    "    models['xgb_hazard'].fit(X_train_dense, y_train_hazard, sample_weight=hazard_sample_weights)\n",
    "    models['xgb_product'].fit(X_train_dense, y_train_product, sample_weight=product_sample_weights)\n",
    "    \n",
    "    predictions['xgb'] = {\n",
    "        'hazard_valid': models['xgb_hazard'].predict(X_valid_dense),\n",
    "        'product_valid': models['xgb_product'].predict(X_valid_dense),\n",
    "        'hazard_test': models['xgb_hazard'].predict(X_test_dense),\n",
    "        'product_test': models['xgb_product'].predict(X_test_dense)\n",
    "    }\n",
    "\n",
    "print(\"All models trained\")\n",
    "\n",
    "# 7. Individual Model Evaluation\n",
    "print(\"\\n6. Individual model evaluation...\")\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "for model_name in predictions.keys():\n",
    "    print(f\"\\n  {model_name.upper()} Results:\")\n",
    "    \n",
    "    # Validation\n",
    "    valid_scores = compute_food_hazard_score(\n",
    "        y_valid_hazard, y_valid_product,\n",
    "        predictions[model_name]['hazard_valid'],\n",
    "        predictions[model_name]['product_valid']\n",
    "    )\n",
    "    \n",
    "    # Test\n",
    "    test_scores = compute_food_hazard_score(\n",
    "        y_test_hazard, y_test_product,\n",
    "        predictions[model_name]['hazard_test'],\n",
    "        predictions[model_name]['product_test']\n",
    "    )\n",
    "    \n",
    "    model_results[model_name] = {\n",
    "        'validation': valid_scores,\n",
    "        'test': test_scores\n",
    "    }\n",
    "    \n",
    "    print(f\"Validation: {valid_scores['final_score']:.4f} (H: {valid_scores['f1_hazards']:.4f}, P: {valid_scores['f1_products']:.4f})\")\n",
    "    print(f\"Test: {test_scores['final_score']:.4f} (H: {test_scores['f1_hazards']:.4f}, P: {test_scores['f1_products']:.4f})\")\n",
    "\n",
    "# 8. Ensemble if requested\n",
    "if CONFIG['ensemble'] and len(predictions) > 1:\n",
    "    print(\"\\n7. Ensemble combination...\")\n",
    "    \n",
    "    from scipy import stats\n",
    "    \n",
    "    # Simple majority voting\n",
    "    ensemble_hazard_valid = []\n",
    "    ensemble_product_valid = []\n",
    "    ensemble_hazard_test = []\n",
    "    ensemble_product_test = []\n",
    "    \n",
    "    for i in range(len(y_valid_hazard)):\n",
    "        hazard_votes = [predictions[model]['hazard_valid'][i] for model in predictions.keys()]\n",
    "        ensemble_hazard_valid.append(stats.mode(hazard_votes, keepdims=True).mode[0])\n",
    "        \n",
    "        product_votes = [predictions[model]['product_valid'][i] for model in predictions.keys()]\n",
    "        ensemble_product_valid.append(stats.mode(product_votes, keepdims=True).mode[0])\n",
    "    \n",
    "    for i in range(len(y_test_hazard)):\n",
    "        hazard_votes = [predictions[model]['hazard_test'][i] for model in predictions.keys()]\n",
    "        ensemble_hazard_test.append(stats.mode(hazard_votes, keepdims=True).mode[0])\n",
    "        \n",
    "        product_votes = [predictions[model]['product_test'][i] for model in predictions.keys()]\n",
    "        ensemble_product_test.append(stats.mode(product_votes, keepdims=True).mode[0])\n",
    "    \n",
    "    # Evaluate ensemble\n",
    "    ensemble_valid = compute_food_hazard_score(\n",
    "        y_valid_hazard, y_valid_product,\n",
    "        np.array(ensemble_hazard_valid), np.array(ensemble_product_valid)\n",
    "    )\n",
    "    \n",
    "    ensemble_test = compute_food_hazard_score(\n",
    "        y_test_hazard, y_test_product,\n",
    "        np.array(ensemble_hazard_test), np.array(ensemble_product_test)\n",
    "    )\n",
    "    \n",
    "    model_results['ensemble'] = {\n",
    "        'validation': ensemble_valid,\n",
    "        'test': ensemble_test\n",
    "    }\n",
    "    \n",
    "    print(f\"ENSEMBLE Results:\")\n",
    "    print(f\"Validation: {ensemble_valid['final_score']:.4f} (H: {ensemble_valid['f1_hazards']:.4f}, P: {ensemble_valid['f1_products']:.4f})\")\n",
    "    print(f\"Test: {ensemble_test['final_score']:.4f} (H: {ensemble_test['f1_hazards']:.4f}, P: {ensemble_test['f1_products']:.4f})\")\n",
    "\n",
    "# 9. Best Model Selection and Final Analysis\n",
    "print(f\"\\n=== FINAL RESULTS COMPARISON ===\")\n",
    "\n",
    "# Find best model\n",
    "best_model = max(model_results.keys(), key=lambda x: model_results[x]['test']['final_score'])\n",
    "best_score = model_results[best_model]['test']['final_score']\n",
    "\n",
    "print(f\"\\nModel Performance Summary:\")\n",
    "for model_name, results in model_results.items():\n",
    "    test_score = results['test']['final_score']\n",
    "    print(f\"  {model_name:15s}: {test_score:.4f}\")\n",
    "\n",
    "print(f\"\\nBEST MODEL: {best_model.upper()}\")\n",
    "print(f\"Best Test Score: {best_score:.4f}\")\n",
    "\n",
    "# Comparison with previous results\n",
    "previous_baseline = 0.5978  # Original TF-IDF result\n",
    "improvement = best_score - previous_baseline\n",
    "\n",
    "print(f\"\\n=== IMPROVEMENT ANALYSIS ===\")\n",
    "print(f\"Previous baseline: {previous_baseline:.4f}\")\n",
    "print(f\"Best new model: {best_score:.4f}\")\n",
    "print(f\"Improvement: {improvement:+.4f}\")\n",
    "\n",
    "if improvement > 0:\n",
    "    print(f\"{improvement:.4f} improvement achieved!\")\n",
    "    if improvement > 0.05:\n",
    "        print(f\"SIGNIFICANT improvement!\")\n",
    "else:\n",
    "    print(f\"{abs(improvement):.4f} decrease\")\n",
    "\n",
    "# Competition comparison\n",
    "if CONFIG['st1_task']:\n",
    "    competition_bert = 0.667\n",
    "    competition_best = 0.8223\n",
    "else:\n",
    "    competition_bert = 0.498\n",
    "    competition_best = 0.5473\n",
    "\n",
    "print(f\"\\nCompetition Comparison ({task_name}):\")\n",
    "print(f\"Competition BERT baseline: {competition_bert:.4f}\")\n",
    "print(f\"Competition best: {competition_best:.4f}\")\n",
    "print(f\"Your best result: {best_score:.4f}\")\n",
    "\n",
    "if best_score > competition_bert:\n",
    "    print(f\"You beat the BERT baseline by {best_score - competition_bert:.4f}!\")\n",
    "else:\n",
    "    gap = competition_bert - best_score\n",
    "    print(f\"Gap to BERT baseline: {gap:.4f}\")\n",
    "\n",
    "# 10. Save Results\n",
    "results_summary = {\n",
    "    'task': task_name,\n",
    "    'method': 'Optimized Simple + Ensemble',\n",
    "    'config': CONFIG,\n",
    "    'tfidf_optimization': tfidf_results if CONFIG['grid_search_tfidf'] else None,\n",
    "    'best_tfidf_config': best_config,\n",
    "    'model_results': model_results,\n",
    "    'best_model': best_model,\n",
    "    'best_score': float(best_score),\n",
    "    'improvement_over_baseline': float(improvement),\n",
    "    'competition_comparison': {\n",
    "        'beats_bert_baseline': bool(best_score > competition_bert),\n",
    "        'gap_to_best': float(competition_best - best_score)\n",
    "    }\n",
    "}\n",
    "\n",
    "filename = f'optimized_results_{task_name.lower()}.json'\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nResults saved to {filename}\")\n",
    "\n",
    "print(f\"\\n=== EXPERIMENT COMPLETED ===\")\n",
    "print(f\"Best {task_name} Score: {best_score:.4f}\")\n",
    "print(f\"Best Model: {best_model}\")\n",
    "\n",
    "# Next steps recommendation\n",
    "print(f\"\\nNEXT STEPS:\")\n",
    "if best_score > competition_bert:\n",
    "    print(\"EXCELLENT! You beat BERT baseline. Try:\")\n",
    "    print(\"1. ST2 with same approach\")\n",
    "    print(\"2. Data augmentation for even better results\")\n",
    "    print(\"3. More advanced ensemble methods\")\n",
    "elif improvement > 0.03:\n",
    "    print(\"Good progress! Try:\")\n",
    "    print(\"1. More XGBoost hyperparameter tuning\")\n",
    "    print(\"2. Different ensemble methods (weighted voting)\")\n",
    "    print(\"3. ST2 application\")\n",
    "else:\n",
    "    print(\"Need different approach. Consider:\")\n",
    "    print(\"1. Data augmentation\")\n",
    "    print(\"2. Different text preprocessing\")\n",
    "    print(\"3. Alternative models (Random Forest)\")\n",
    "\n",
    "print(f\"\\nCurrent distance to competition:\")\n",
    "print(f\"BERT baseline: {max(0, competition_bert - best_score):.3f} points away\")\n",
    "print(f\"Best result: {competition_best - best_score:.3f} points away\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
