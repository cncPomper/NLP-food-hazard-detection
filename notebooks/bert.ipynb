{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f58c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy pandas transformers scikit-learn hf_xet 'accelerate>=0.26.0' datasets\n",
    "# %pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac701340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "script_dir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "parent_dir = os.path.abspath(os.path.join(script_dir, os.pardir))\n",
    "sys.path.append(script_dir)\n",
    "from utils import *\n",
    "from dataset.simple_dataset import *\n",
    "from models.simple_bert import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "print(\"=== SIMPLE FOOD HAZARD DETECTION - COMPATIBILITY MODE ===\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Configuration - Ultra simple\n",
    "CONFIG = {\n",
    "    'st1_task': True,  # Change to False for ST2\n",
    "    'use_bert': False,  # Set to True if you want to try BERT\n",
    "    'max_features': 10000,  # TF-IDF features\n",
    "    'test_bert_loading': False  # Test if BERT loading works\n",
    "}\n",
    "\n",
    "# Configuration - Ultra simple\n",
    "# CONFIG = {\n",
    "#     'st1_task': False,  # Change to False for ST2\n",
    "#     'use_bert': False,  # Set to True if you want to try BERT\n",
    "#     'max_features': 10000,  # TF-IDF features\n",
    "#     'test_bert_loading': False  # Test if BERT loading works\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e419d",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b16c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n1. Loading data...\")\n",
    "\n",
    "DATA_PATH = \"https://github.com/food-hazard-detection-semeval-2025/food-hazard-detection-semeval-2025.github.io/blob/main/data/\"\n",
    "\n",
    "train = pd.read_csv(os.path.join(DATA_PATH, \"incidents_train.csv?raw=true\"))\n",
    "valid = pd.read_csv(os.path.join(DATA_PATH, \"incidents_valid.csv?raw=true\"))\n",
    "test = pd.read_csv(os.path.join(DATA_PATH, \"incidents_test.csv?raw=true\"))\n",
    "\n",
    "task_name = \"ST1\" if CONFIG['st1_task'] else \"ST2\"\n",
    "print(f\"Task: {task_name}\")\n",
    "print(f\"Method: {'BERT' if CONFIG['use_bert'] else 'TF-IDF + LogReg'}\")\n",
    "\n",
    "print(f\"Data loaded - Train: {len(train)}, Valid: {len(valid)}, Test: {len(test)}\")\n",
    "\n",
    "# Select columns based on task\n",
    "if CONFIG['st1_task']:\n",
    "    hazard_col = 'hazard-category'\n",
    "    product_col = 'product-category'\n",
    "else:\n",
    "    hazard_col = 'hazard'\n",
    "    product_col = 'product'\n",
    "\n",
    "print(f\"Target columns: {hazard_col}, {product_col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cfa702",
   "metadata": {},
   "source": [
    "### 2. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3e3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n2. Data analysis...\")\n",
    "hazard_counts = train[hazard_col].value_counts()\n",
    "product_counts = train[product_col].value_counts()\n",
    "\n",
    "print(f\"Hazard classes: {len(hazard_counts)}\")\n",
    "print(f\"Product classes: {len(product_counts)}\")\n",
    "print(f\"Most common hazard: {hazard_counts.index[0]} ({hazard_counts.iloc[0]} samples)\")\n",
    "print(f\"Most common product: {product_counts.index[0]} ({product_counts.iloc[0]} samples)\")\n",
    "\n",
    "# Check for imbalance\n",
    "imbalance_ratio_h = hazard_counts.iloc[0] / hazard_counts.iloc[-1]\n",
    "imbalance_ratio_p = product_counts.iloc[0] / product_counts.iloc[-1]\n",
    "print(f\"Hazard imbalance ratio: {imbalance_ratio_h:.1f}x\")\n",
    "print(f\"Product imbalance ratio: {imbalance_ratio_p:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34223835",
   "metadata": {},
   "source": [
    "### 3. Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580757d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n3. Text preparation...\")\n",
    "\n",
    "train_texts = prepare_text(train)\n",
    "valid_texts = prepare_text(valid)\n",
    "test_texts = prepare_text(test)\n",
    "\n",
    "print(f\"Texts prepared - Average length: {np.mean([len(t.split()) for t in train_texts[:100]]):.1f} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01715d2c",
   "metadata": {},
   "source": [
    "### 4. Test BERT loading if requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77d0ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG['test_bert_loading']:\n",
    "    print(\"\\n4. Testing BERT loading...\")\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')  # Lighter model\n",
    "        model = AutoModel.from_pretrained('distilbert-base-uncased')\n",
    "        print(\"BERT loading successful! You can set use_bert=True\")\n",
    "        CONFIG['use_bert'] = True\n",
    "    except Exception as e:\n",
    "        print(f\"BERT loading failed: {e}\")\n",
    "        print(\"Continuing with TF-IDF...\")\n",
    "        CONFIG['use_bert'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bb8188",
   "metadata": {},
   "source": [
    "### 5. Model Training - TF-IDF Version (Always works)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5301d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CONFIG['use_bert']:\n",
    "    print(\"\\n5. Training TF-IDF + LogReg model...\")\n",
    "    \n",
    "    # TF-IDF Vectorization\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=CONFIG['max_features'],\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=2,\n",
    "        max_df=0.95,\n",
    "        stop_words='english'\n",
    "    )\n",
    "    \n",
    "    print(\"Creating TF-IDF features...\")\n",
    "    X_train = vectorizer.fit_transform(train_texts)\n",
    "    X_valid = vectorizer.transform(valid_texts)\n",
    "    X_test = vectorizer.transform(test_texts)\n",
    "    \n",
    "    print(f\"TF-IDF shape: {X_train.shape}\")\n",
    "    \n",
    "    # Prepare labels\n",
    "    y_train_hazard = train[hazard_col].values\n",
    "    y_valid_hazard = valid[hazard_col].values\n",
    "    y_test_hazard = test[hazard_col].values\n",
    "    \n",
    "    y_train_product = train[product_col].values\n",
    "    y_valid_product = valid[product_col].values\n",
    "    y_test_product = test[product_col].values\n",
    "    \n",
    "    # Class weights for imbalanced data\n",
    "    hazard_classes = np.unique(y_train_hazard)\n",
    "    product_classes = np.unique(y_train_product)\n",
    "    \n",
    "    hazard_weights = compute_class_weight('balanced', classes=hazard_classes, y=y_train_hazard)\n",
    "    product_weights = compute_class_weight('balanced', classes=product_classes, y=y_train_product)\n",
    "    \n",
    "    hazard_weight_dict = dict(zip(hazard_classes, hazard_weights))\n",
    "    product_weight_dict = dict(zip(product_classes, product_weights))\n",
    "    \n",
    "    print(f\"Class weights computed - Hazard: {len(hazard_weight_dict)}, Product: {len(product_weight_dict)}\")\n",
    "    \n",
    "    # Train models\n",
    "    print(\"Training hazard classifier...\")\n",
    "    hazard_model = LogisticRegression(\n",
    "        class_weight=hazard_weight_dict,\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    )\n",
    "    hazard_model.fit(X_train, y_train_hazard)\n",
    "    \n",
    "    print(\"Training product classifier...\")\n",
    "    product_model = LogisticRegression(\n",
    "        class_weight=product_weight_dict,\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    )\n",
    "    product_model.fit(X_train, y_train_product)\n",
    "    \n",
    "    print(\"Models trained\")\n",
    "    \n",
    "    # Predictions\n",
    "    print(\"\\n6. Making predictions...\")\n",
    "    hazard_pred_valid = hazard_model.predict(X_valid)\n",
    "    product_pred_valid = product_model.predict(X_valid)\n",
    "    \n",
    "    hazard_pred_test = hazard_model.predict(X_test)\n",
    "    product_pred_test = product_model.predict(X_test)\n",
    "    \n",
    "# Simple BERT Version (if compatible)\n",
    "elif CONFIG['use_bert']:\n",
    "    print(\"\\n5. Training Simple BERT...\")\n",
    "        \n",
    "    # Initialize\n",
    "    tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    \n",
    "    train_dataset = SimpleDataset(train_texts, train[hazard_col].values, train[product_col].values, tokenizer)\n",
    "    valid_dataset = SimpleDataset(valid_texts, valid[hazard_col].values, valid[product_col].values, tokenizer)\n",
    "    test_dataset = SimpleDataset(test_texts, test[hazard_col].values, test[product_col].values, tokenizer)\n",
    "    \n",
    "    model = SimpleBERT('distilbert-base-uncased', len(train_dataset.hazard_to_id), len(train_dataset.product_to_id))\n",
    "    \n",
    "    # Simple training (just 1 epoch for demo)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    print(\"Training (1 epoch for demo)...\")\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        if batch_idx > 50:  # Just first 50 batches for demo\n",
    "            break\n",
    "            \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        hazard_labels = batch['hazard_label'].to(device)\n",
    "        product_labels = batch['product_label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hazard_logits, product_logits = model(input_ids, attention_mask)\n",
    "        \n",
    "        loss = criterion(hazard_logits, hazard_labels) + criterion(product_logits, product_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Batch {batch_idx}/50, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    print(\"BERT training completed (demo)\")\n",
    "    \n",
    "    # Simple predictions for BERT would go here...\n",
    "    # For now, fall back to TF-IDF results\n",
    "    print(\"  Note: Using TF-IDF results for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67db99a2",
   "metadata": {},
   "source": [
    "### 7. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n7. Evaluation...\")\n",
    "\n",
    "# Validation results\n",
    "valid_scores = compute_food_hazard_score(\n",
    "    y_valid_hazard, y_valid_product,\n",
    "    hazard_pred_valid, product_pred_valid\n",
    ")\n",
    "\n",
    "# Test results  \n",
    "test_scores = compute_food_hazard_score(\n",
    "    y_test_hazard, y_test_product,\n",
    "    hazard_pred_test, product_pred_test\n",
    ")\n",
    "\n",
    "print(\"\\n=== VALIDATION RESULTS ===\")\n",
    "print(f\"Hazard F1: {valid_scores['f1_hazards']:.4f}\")\n",
    "print(f\"Product F1: {valid_scores['f1_products']:.4f}\")\n",
    "print(f\"Final Score: {valid_scores['final_score']:.4f}\")\n",
    "\n",
    "print(\"\\n=== TEST RESULTS ===\")\n",
    "print(f\"Hazard F1: {test_scores['f1_hazards']:.4f}\")\n",
    "print(f\"Product F1: {test_scores['f1_products']:.4f}\")\n",
    "print(f\"Final Score: {test_scores['final_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7922f15a",
   "metadata": {},
   "source": [
    "### 8. Comparison with baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6bf398",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n8. Baseline comparison...\")\n",
    "\n",
    "# Majority classifier\n",
    "dummy_hazard = DummyClassifier(strategy='most_frequent')\n",
    "dummy_product = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "dummy_hazard.fit(X_train, y_train_hazard)\n",
    "dummy_product.fit(X_train, y_train_product)\n",
    "\n",
    "dummy_hazard_pred = dummy_hazard.predict(X_test)\n",
    "dummy_product_pred = dummy_product.predict(X_test)\n",
    "\n",
    "dummy_scores = compute_food_hazard_score(\n",
    "    y_test_hazard, y_test_product,\n",
    "    dummy_hazard_pred, dummy_product_pred\n",
    ")\n",
    "\n",
    "print(f\"Majority Baseline: {dummy_scores['final_score']:.4f}\")\n",
    "print(f\"Our Model: {test_scores['final_score']:.4f}\")\n",
    "print(f\"Improvement: +{test_scores['final_score'] - dummy_scores['final_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7788b2",
   "metadata": {},
   "source": [
    "### 9. Competition comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64428da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== COMPETITION COMPARISON ({task_name}) ===\")\n",
    "if CONFIG['st1_task']:\n",
    "    competition_best = 0.8223\n",
    "    competition_bert = 0.667\n",
    "    print(f\"Competition Best (Anastasia): {competition_best:.4f}\")\n",
    "    print(f\"Competition BERT Baseline: {competition_bert:.4f}\")\n",
    "else:\n",
    "    competition_best = 0.5473\n",
    "    competition_bert = 0.498\n",
    "    print(f\"Competition Best (SRCB): {competition_best:.4f}\")\n",
    "    print(f\"Competition BERT Baseline: {competition_bert:.4f}\")\n",
    "\n",
    "print(f\"Your Result: {test_scores['final_score']:.4f}\")\n",
    "\n",
    "if CONFIG['st1_task']:\n",
    "    if test_scores['final_score'] > competition_bert:\n",
    "        print(f\"You beat the BERT baseline by {test_scores['final_score'] - competition_bert:.4f}!\")\n",
    "    gap_to_best = competition_best - test_scores['final_score']\n",
    "    print(f\"Gap to best: {gap_to_best:.4f}\")\n",
    "else:\n",
    "    if test_scores['final_score'] > competition_bert:\n",
    "        print(f\"You beat the BERT baseline by {test_scores['final_score'] - competition_bert:.4f}!\")\n",
    "    gap_to_best = competition_best - test_scores['final_score']\n",
    "    print(f\"Gap to best: {gap_to_best:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d9b440",
   "metadata": {},
   "source": [
    "### 10. Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b572033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary = {\n",
    "    'task': task_name,\n",
    "    'method': 'TF-IDF + LogReg with Class Weights',\n",
    "    'config': CONFIG,\n",
    "    'data_stats': {\n",
    "        'train_size': len(train),\n",
    "        'valid_size': len(valid),\n",
    "        'test_size': len(test),\n",
    "        'hazard_classes': len(hazard_counts),\n",
    "        'product_classes': len(product_counts),\n",
    "        'hazard_imbalance': float(imbalance_ratio_h),\n",
    "        'product_imbalance': float(imbalance_ratio_p)\n",
    "    },\n",
    "    'results': {\n",
    "        'validation': valid_scores,\n",
    "        'test': test_scores,\n",
    "        'baseline': dummy_scores,\n",
    "        'improvement': float(test_scores['final_score'] - dummy_scores['final_score'])\n",
    "    },\n",
    "    'competition_comparison': {\n",
    "        'competition_best': float(competition_best),\n",
    "        'competition_bert': float(competition_bert),\n",
    "        'our_result': float(test_scores['final_score']),\n",
    "        'gap_to_best': float(competition_best - test_scores['final_score'])\n",
    "    }\n",
    "}\n",
    "\n",
    "filename = f'simple_results_{task_name.lower()}.json'\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nResults saved to {filename}\")\n",
    "\n",
    "print(\"\\n=== EXPERIMENT COMPLETED ===\")\n",
    "print(\"Method: TF-IDF + Logistic Regression\")\n",
    "print(f\"Final {task_name} Score: {test_scores['final_score']:.4f}\")\n",
    "\n",
    "# Quick suggestions for improvement\n",
    "print(\"\\nNEXT STEPS FOR BETTER RESULTS:\")\n",
    "print(\"1. Try different TF-IDF parameters (max_features, ngram_range)\")\n",
    "print(\"2. Add more feature engineering (text length, country, date)\")\n",
    "print(\"3. Try ensemble methods (combine multiple models)\")\n",
    "print(\"4. If BERT works, try: 'test_bert_loading': True\")\n",
    "print(\"5. For ST2 task, set: 'st1_task': False\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
